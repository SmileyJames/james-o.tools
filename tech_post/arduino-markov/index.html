<!doctype html><html><head><title>The Learning Line Follower â—€ James O'Toole</title><link rel=stylesheet type=text/css href=/main.css><meta name=description content="Be warned, this tale is a tragedy.
For Christmas, my father bought me an Arduino robot kit with 4 wheels some eyes and ears. It came with light (and sonar) sensors. I decided to conduct supervised learning with a Markov chain model. Two front light sensor point vertically down, reading the grounds ability to reflect infrared light. The kit came with black tape to lay on the floor. I aimed to teach the robot to follow the line, programming it to remember 1KB: a weighted guess at a set of movements given the last two things it saw (input reads)."><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"></head><body><div id=content class=container><header class="blog-header py-3"><div class="row flex-nowrap justify-content-between align-items-center"><div class="col-4 pt-1"></div><div class="col-4 text-center"><a class="blog-header-logo text-dark" href=/>James O'Toole</a></div><div class="col-4 pt-1 d-flex justify-content-end align-items-center"></div></div></header><div class="nav-scroller py-1 mb-2"><nav class="nav d-flex justify-content-between"><a class="p-2 text-muted" href=/contact>Contact</a>
<a class="p-2 text-muted" href=/tech_post>Tech Blog</a>
<a class="p-2 text-muted" href=/art_post>Art Portfolio</a>
<a class="p-2 text-muted" href=https://www.github.com/SmileyJames/>Github</a></nav></div><div class=row><div class=col-12><h2>The Learning Line Follower</h2></div></div><div class=row><div class="col-md-10 col-lg-7 col-xl-5"><div class=row><div class=col-6><p class=text-muted>James O'Toole</p></div><div class="col-6 text-right"><p class=text-muted>Mar 1 2020</p></div></div><p>Be warned, this tale is a tragedy.</p><p>For Christmas, my father bought me an Arduino robot kit with 4 wheels some eyes and ears. It came with light (and sonar) sensors. I decided to conduct supervised learning with a <a href=https://en.wikipedia.org/wiki/Markov_chain>Markov chain</a> model. Two front light sensor point vertically down, reading the grounds ability to reflect infrared light. The kit came with black tape to lay on the floor. I aimed to teach the robot to follow the line, programming it to remember 1KB: a weighted guess at a set of movements given the last two things it saw (input reads). The code I wrote is in this <a href=https://github.com/SmileyJames/arduino_markov>code repository</a>.</p><p>I built the robot following the Ikea like instructions, easy stuff (think electronic Lego and a little Mechano). After a period of writing the program&rsquo;s first draft and some debugging, I let the dumb buggy loose in the kitchen, starting with It&rsquo;s eyeballs to the black tape circuit. I switch it on and click on my remote to start - It trashed violently with a preference to always drive backwards, I rewarded it with &lsquo;up arrow&rsquo; remote control clicks if it ever went forward and punished with &lsquo;down arrow&rsquo; clicks when it went backwards or turned the wrong way. It seemed like behaviour initially went well and then suddenly only went forwards - speeding towards the door frame.</p><p>I was ecstatic with the outcome (crashes aside) - it had had a go and even got a little better for a bit, however clearly the program needed a little bit of work. A few iterations and I discovered a number of issues relating to integer overflow, especially in the . Some trial and error in the kitchen helped me tweak some (run-time static) variables.</p><p>This yielded reasonable results. After half an hour of training the robot went forward and attempted the corner a majority of times. I thought a simple hand programmed - a non-learning approach could probably beat it.</p><p>One faces problems when working on a device with a small memory footprint. Once It learns that 1 choice is 100% likely, given a scenario of input, it will make the choice again and then either be punished or rewarded - here it is hard to decide how the program to operate. One option is to stop making changes. My solution attempts some &ldquo;easing&rdquo;, allowing 100 - 0 choices change - there is an argument that this is sub optimal.</p><p>With regular training and saving the model to persistent storage, the robot started to make good progress. I was pleased with the results and continuing to make small improvements to the code.</p><p>Then the battery died, and wouldn&rsquo;t recharge.</p></div></div><footer class="mt-5 text-center"><p>Copyright of James O'Toole</p><p>All opinion expressed is my own not my employers.</p><p><a href=mailto:contact@james-o.tools>contact@james-o.tools</a></p><p><a href=#>Back to top</a></p></footer></div></body></html>